{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing IPU resources from notebooks\n",
    "\n",
    "The execution model of IPUs and notebooks means that as you experiment with different models\n",
    "you might keep hold of hardware in an idle state, preventing other users from using it. Or\n",
    "your experiments might fail because you have insufficient hardware.\n",
    "Releasing hardware is particularly important in notebooks as the long life time of the\n",
    "underlying `ipython` kernel can keep a lock on IPUs long after you are done interacting\n",
    "with the hardware.\n",
    "\n",
    "The Graphcore frameworks operate a computational architecture of 1 model = 1 IPU device;\n",
    "this means that each model will attach to specific IPUs and will only release them when\n",
    "that model goes out of scope or when resources are explicitly released.\n",
    "\n",
    "In this notebook you will learn:\n",
    "\n",
    "- to monitor how many IPUs your notebook is currently using\n",
    "- to release IPUs by detaching a model\n",
    "- to reattach a model to IPUs, to continue using a model after a period of inactivity.\n",
    "\n",
    "For more information on the basics of IPU computational architecture you may want to read\n",
    "the [IPU Programmer's Guide](https://docs.graphcore.ai/projects/ipu-programmers-guide/en/latest/ipu_introduction.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In order to run this demo you will need Optimum Graphcore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's make sure your environment has the latest version of [ü§ó Optimum Graphcore](https://github.com/huggingface/optimum-graphcore) available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:34:52.471006Z",
     "iopub.status.busy": "2023-01-15T22:34:52.470743Z",
     "iopub.status.idle": "2023-01-15T22:34:54.726502Z",
     "shell.execute_reply": "2023-01-15T22:34:54.725702Z",
     "shell.execute_reply.started": "2023-01-15T22:34:52.470980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimum-graphcore<0.5,>=0.4\n",
      "  Downloading optimum_graphcore-0.4.3-py3-none-any.whl (180 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m180.6/180.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from optimum-graphcore<0.5,>=0.4) (9.4.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from optimum-graphcore<0.5,>=0.4) (0.1.97)\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.8/dist-packages (from optimum-graphcore<0.5,>=0.4) (0.12.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (from optimum-graphcore<0.5,>=0.4) (2.8.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from optimum-graphcore<0.5,>=0.4) (1.10.0)\n",
      "Requirement already satisfied: optimum in /usr/local/lib/python3.8/dist-packages (from optimum-graphcore<0.5,>=0.4) (1.6.1)\n",
      "Requirement already satisfied: transformers==4.20.1 in /usr/local/lib/python3.8/dist-packages (from optimum-graphcore<0.5,>=0.4) (4.20.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from optimum-graphcore<0.5,>=0.4) (1.13.0+cpu)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.1->optimum-graphcore<0.5,>=0.4) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.1->optimum-graphcore<0.5,>=0.4) (1.23.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.1->optimum-graphcore<0.5,>=0.4) (2.28.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.1->optimum-graphcore<0.5,>=0.4) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.1->optimum-graphcore<0.5,>=0.4) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.1->optimum-graphcore<0.5,>=0.4) (0.11.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.1->optimum-graphcore<0.5,>=0.4) (2022.10.31)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.1->optimum-graphcore<0.5,>=0.4) (22.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets->optimum-graphcore<0.5,>=0.4) (3.2.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets->optimum-graphcore<0.5,>=0.4) (0.18.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets->optimum-graphcore<0.5,>=0.4) (1.5.2)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets->optimum-graphcore<0.5,>=0.4) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets->optimum-graphcore<0.5,>=0.4) (2022.11.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets->optimum-graphcore<0.5,>=0.4) (10.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets->optimum-graphcore<0.5,>=0.4) (3.8.3)\n",
      "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets->optimum-graphcore<0.5,>=0.4) (0.3.6)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from optimum->optimum-graphcore<0.5,>=0.4) (1.11.1)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.8/dist-packages (from optimum->optimum-graphcore<0.5,>=0.4) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->optimum-graphcore<0.5,>=0.4) (4.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->optimum-graphcore<0.5,>=0.4) (22.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->optimum-graphcore<0.5,>=0.4) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->optimum-graphcore<0.5,>=0.4) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->optimum-graphcore<0.5,>=0.4) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->optimum-graphcore<0.5,>=0.4) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->optimum-graphcore<0.5,>=0.4) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->optimum-graphcore<0.5,>=0.4) (6.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==4.20.1->optimum-graphcore<0.5,>=0.4) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers==4.20.1->optimum-graphcore<0.5,>=0.4) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.20.1->optimum-graphcore<0.5,>=0.4) (1.26.14)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.20.1->optimum-graphcore<0.5,>=0.4) (3.20.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.8/dist-packages (from coloredlogs->optimum->optimum-graphcore<0.5,>=0.4) (10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->optimum-graphcore<0.5,>=0.4) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->optimum-graphcore<0.5,>=0.4) (2022.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->optimum->optimum-graphcore<0.5,>=0.4) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum-graphcore<0.5,>=0.4) (1.14.0)\n",
      "Installing collected packages: optimum-graphcore\n",
      "  Attempting uninstall: optimum-graphcore\n",
      "    Found existing installation: optimum-graphcore 0.5.0\n",
      "    Uninstalling optimum-graphcore-0.5.0:\n",
      "      Successfully uninstalled optimum-graphcore-0.5.0\n",
      "Successfully installed optimum-graphcore-0.4.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"optimum-graphcore>=0.4, <0.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:35:01.021292Z",
     "iopub.status.busy": "2023-01-15T22:35:01.021032Z",
     "iopub.status.idle": "2023-01-15T22:35:01.024446Z",
     "shell.execute_reply": "2023-01-15T22:35:01.023841Z",
     "shell.execute_reply.started": "2023-01-15T22:35:01.021272Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring resources\n",
    "\n",
    "Grapchore provides the `gc-monitor` utility for inspecting the number of available IPUs and their usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:35:03.393505Z",
     "iopub.status.busy": "2023-01-15T22:35:03.393264Z",
     "iopub.status.idle": "2023-01-15T22:35:03.626564Z",
     "shell.execute_reply": "2023-01-15T22:35:03.625742Z",
     "shell.execute_reply.started": "2023-01-15T22:35:03.393487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------------------------------------------------------------------+\n",
      "|  gc-monitor   |         Partition: lr17-1-poplar-19 [active] has 4 reconfigurable IPUs          |\n",
      "+-------------+--------------------+--------+--------------+----------+-------+----+------+-------+\n",
      "|    IPU-M    |       Serial       |IPU-M SW|Server version|  ICU FW  | Type  | ID | IPU# |Routing|\n",
      "+-------------+--------------------+--------+--------------+----------+-------+----+------+-------+\n",
      "|  10.5.18.3  | 0055.0002.8204821  | 2.6.0  |    1.11.0    |  2.5.9   | M2000 | 0  |  3   |  DNC  |\n",
      "|  10.5.18.3  | 0055.0002.8204821  | 2.6.0  |    1.11.0    |  2.5.9   | M2000 | 1  |  2   |  DNC  |\n",
      "|  10.5.18.3  | 0055.0001.8204821  | 2.6.0  |    1.11.0    |  2.5.9   | M2000 | 2  |  1   |  DNC  |\n",
      "|  10.5.18.3  | 0055.0001.8204821  | 2.6.0  |    1.11.0    |  2.5.9   | M2000 | 3  |  0   |  DNC  |\n",
      "+-------------+--------------------+--------+--------------+----------+-------+----+------+-------+\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "|                       No attached processes in partition lr17-1-poplar-19                        |\n",
      "+--------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!gc-monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a notebook, we can run this Bash command using `!` in a regular code cell. It provides detailed information on the IPUs that exist in the current partition.\n",
    "The first section of the output is the `card-info`, this is generic information about the IP addresses and serial numbers of all the cards visible to the process.\n",
    "The second section of the output indicates usage information of the IPU: it will indicate the user, host and PID which are attached to the different IPUs.\n",
    "\n",
    "When monitoring IPUs it can be useful to run `gc-monitor` without displaying the static IPU information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:35:31.967505Z",
     "iopub.status.busy": "2023-01-15T22:35:31.967232Z",
     "iopub.status.idle": "2023-01-15T22:35:32.195720Z",
     "shell.execute_reply": "2023-01-15T22:35:32.194940Z",
     "shell.execute_reply.started": "2023-01-15T22:35:31.967483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------+\n",
      "|                       No attached processes in partition lr17-1-poplar-19                        |\n",
      "+--------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!gc-monitor --no-card-info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can write a command that will monitor only the IPUs which are attached from this specific notebook. We do that by only displaying the IPUs attached to a specific PID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:35:38.001513Z",
     "iopub.status.busy": "2023-01-15T22:35:38.001237Z",
     "iopub.status.idle": "2023-01-15T22:35:38.231427Z",
     "shell.execute_reply": "2023-01-15T22:35:38.230612Z",
     "shell.execute_reply.started": "2023-01-15T22:35:38.001491Z"
    }
   },
   "outputs": [],
   "source": [
    "!gc-monitor --no-card-info | grep ${os.getpid()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we've not attached to any IPUs yet, there is no output.\n",
    "\n",
    "Beyond `gc-monitor`, Graphcore also provides a library for monitoring usage called `gcipuinfo` which can be used in Python. This library is not covered in this tutorial but [examples are available in the documentation](https://docs.graphcore.ai/projects/gcipuinfo/en/latest/examples.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating models\n",
    "\n",
    "Now let's create some models and attach them to IPUs. The simplest way to create a small model is using the inference `pipeline` provided by the `optimum-graphcore` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:35:53.513913Z",
     "iopub.status.busy": "2023-01-15T22:35:53.513664Z",
     "iopub.status.idle": "2023-01-15T22:36:39.580372Z",
     "shell.execute_reply": "2023-01-15T22:36:39.579696Z",
     "shell.execute_reply.started": "2023-01-15T22:35:53.513891Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32160af8c23f4ffa978bfce823baf393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45bde2a30d043dc81ffbf1cfb33f305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fac9dedb1f49bd9e5797283ace1258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/699 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/optimum/graphcore/ipu_configuration.py:148: UserWarning: The \"enable_half_first_order_momentum\" parameter is deprecated\n",
      "  warnings.warn('The \"enable_half_first_order_momentum\" parameter is deprecated')\n",
      "/usr/local/lib/python3.8/dist-packages/optimum/graphcore/ipu_configuration.py:140: UserWarning: The \"sharded_execution_for_inference\" parameter is deprecated, sharded execution is always used during inference\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b234d0666fa64933ae213b19ca27eeee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb939d5a9dc4a858b933aea388711dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f26dc5ad84413c975905c3cd63dcb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No padding arguments specified, so pad to 128 by default. Inputs longer than 128 will be truncated. To change this behaviour, pass the `padding='max_length'` and`max_length=<your desired input length>` arguments to the pipeline function\n",
      "Graph compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:29<00:00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998313188552856},\n",
       " {'label': 'POSITIVE', 'score': 0.972362220287323}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optimum.graphcore import pipelines\n",
    "sentiment_pipeline = pipelines.pipeline(\"sentiment-analysis\")\n",
    "sentiment_pipeline([\"IPUs are great!\", \"Notebooks are easy to program in\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:39:55.889387Z",
     "iopub.status.busy": "2023-01-15T22:39:55.889092Z",
     "iopub.status.idle": "2023-01-15T22:39:55.921025Z",
     "shell.execute_reply": "2023-01-15T22:39:55.920378Z",
     "shell.execute_reply.started": "2023-01-15T22:39:55.889365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9997872710227966},\n",
       " {'label': 'POSITIVE', 'score': 0.972362220287323},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997872710227966},\n",
       " {'label': 'POSITIVE', 'score': 0.972362220287323},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997872710227966},\n",
       " {'label': 'POSITIVE', 'score': 0.972362220287323},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997872710227966},\n",
       " {'label': 'POSITIVE', 'score': 0.972362220287323},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997872710227966},\n",
       " {'label': 'POSITIVE', 'score': 0.972362220287323},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997872710227966},\n",
       " {'label': 'POSITIVE', 'score': 0.972362220287323},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997872710227966},\n",
       " {'label': 'POSITIVE', 'score': 0.972362220287323},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997872710227966},\n",
       " {'label': 'POSITIVE', 'score': 0.972362220287323}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(8*[\"poor effect.\", \"Notebooks are easy to program in\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check how many IPUs are in use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:40:13.118544Z",
     "iopub.status.busy": "2023-01-15T22:40:13.118274Z",
     "iopub.status.idle": "2023-01-15T22:40:13.471717Z",
     "shell.execute_reply": "2023-01-15T22:40:13.470944Z",
     "shell.execute_reply.started": "2023-01-15T22:40:13.118524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------------------------------------------------------------------+\n",
      "|  gc-monitor   |         Partition: lr17-1-poplar-19 [active] has 4 reconfigurable IPUs          |\n",
      "+-------------+--------------------+--------+--------------+----------+-------+----+------+-------+\n",
      "|    IPU-M    |       Serial       |IPU-M SW|Server version|  ICU FW  | Type  | ID | IPU# |Routing|\n",
      "+-------------+--------------------+--------+--------------+----------+-------+----+------+-------+\n",
      "|  10.5.18.3  | 0055.0002.8204821  | 2.6.0  |    1.11.0    |  2.5.9   | M2000 | 0  |  3   |  DNC  |\n",
      "|  10.5.18.3  | 0055.0002.8204821  | 2.6.0  |    1.11.0    |  2.5.9   | M2000 | 1  |  2   |  DNC  |\n",
      "|  10.5.18.3  | 0055.0001.8204821  | 2.6.0  |    1.11.0    |  2.5.9   | M2000 | 2  |  1   |  DNC  |\n",
      "|  10.5.18.3  | 0055.0001.8204821  | 2.6.0  |    1.11.0    |  2.5.9   | M2000 | 3  |  0   |  DNC  |\n",
      "+-------------+--------------------+--------+--------------+----------+-------+----+------+-------+\n",
      "+-----------------------------------+------------------------+-----------------+\n",
      "|...es in partition lr17-1-poplar-19|          IPU           |      Board      |\n",
      "+--------+----+--------+------------+----+----------+--------+--------+--------+\n",
      "|  PID   |...d|  Time  |    User    | ID |  Clock   |  Temp  |  Temp  | Power  |\n",
      "+--------+----+--------+------------+----+----------+--------+--------+--------+\n",
      "|  1119  |...3| 6m16s  |    root    | 0  | 1330MHz  | 36.3 C | 28.1 C |153.9 W |\n",
      "|  1119  |...3| 6m16s  |    root    | 1  | 1330MHz  | 33.2 C |        |        |\n",
      "+--------+----+--------+------------+----+----------+--------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "!gc-monitor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:39:52.522908Z",
     "iopub.status.busy": "2023-01-15T22:39:52.522528Z",
     "iopub.status.idle": "2023-01-15T22:39:52.878263Z",
     "shell.execute_reply": "2023-01-15T22:39:52.877477Z",
     "shell.execute_reply.started": "2023-01-15T22:39:52.522888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  1119  |...3| 5m55s  |    root    | 0  | 1330MHz  | 36.2 C | 28.0 C |153.4 W |\n",
      "|  1119  |...3| 5m55s  |    root    | 1  | 1330MHz  | 33.3 C |        |        |\n"
     ]
    }
   ],
   "source": [
    "!gc-monitor --no-card-info | grep ${os.getpid()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These IPUs will be associated with the model in the pipeline until:\n",
    "\n",
    "- The `sentiment_pipeline` object goes out of scope or\n",
    "- The model is explicitly detached from the IPU.\n",
    "\n",
    "By remaining attached the model can be very fast, providing fast responses to new prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:43:21.189632Z",
     "iopub.status.busy": "2023-01-15T22:43:21.189373Z",
     "iopub.status.idle": "2023-01-15T22:43:28.201361Z",
     "shell.execute_reply": "2023-01-15T22:43:28.200674Z",
     "shell.execute_reply.started": "2023-01-15T22:43:21.189613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.3 ms ¬± 105 ¬µs per loop (mean ¬± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sentiment_pipeline(32*[\"IPUs are fast once the pipeline is attached\", \"and Notebooks are easy to program in\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are testing different models you might have multiple pipelines using IPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:43:30.930474Z",
     "iopub.status.busy": "2023-01-15T22:43:30.930224Z",
     "iopub.status.idle": "2023-01-15T22:43:40.192755Z",
     "shell.execute_reply": "2023-01-15T22:43:40.192236Z",
     "shell.execute_reply.started": "2023-01-15T22:43:30.930455Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No padding arguments specified, so pad to 128 by default. Inputs longer than 128 will be truncated. To change this behaviour, pass the `padding='max_length'` and`max_length=<your desired input length>` arguments to the pipeline function\n",
      "Graph compilation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998313188552856},\n",
       " {'label': 'POSITIVE', 'score': 0.972362220287323}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline_2 = pipelines.pipeline(\"text-classification\")\n",
    "sentiment_pipeline_2([\"IPUs are great!\", \"Notebooks are easy to program in\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the IPU usage we can see that we are now using four IPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:43:42.453177Z",
     "iopub.status.busy": "2023-01-15T22:43:42.452930Z",
     "iopub.status.idle": "2023-01-15T22:43:42.878721Z",
     "shell.execute_reply": "2023-01-15T22:43:42.877930Z",
     "shell.execute_reply.started": "2023-01-15T22:43:42.453158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  1119  |...3| 9m45s  |    root    | 0  | 1330MHz  | 36.6 C | 28.0 C |153.2 W |\n",
      "|  1119  |...3| 9m45s  |    root    | 1  | 1330MHz  | 33.6 C |        |        |\n",
      "|  1119  |...3| 9m45s  |    root    | 2  | 1330MHz  | 39.1 C |        |        |\n",
      "|  1119  |...3| 9m45s  |    root    | 3  | 1330MHz  | 36.2 C |        |        |\n"
     ]
    }
   ],
   "source": [
    "!gc-monitor --no-card-info | grep ${os.getpid()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing resources\n",
    "\n",
    "From this we see that we are using four IPUs, two per active pipeline. While it may make sense for us to keep both pipelines active if we are testing both at the same time, we may need to free up resources to continue experimenting with more models.\n",
    "\n",
    "To do that we can call the `detachFromDevice` method on the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:44:00.056038Z",
     "iopub.status.busy": "2023-01-15T22:44:00.055798Z",
     "iopub.status.idle": "2023-01-15T22:44:00.210823Z",
     "shell.execute_reply": "2023-01-15T22:44:00.209935Z",
     "shell.execute_reply.started": "2023-01-15T22:44:00.056017Z"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "'poptorch_py_error': Device is not attached",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8afb684ef9c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentiment_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetachFromDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/poptorch/_poplar_executor.py\u001b[0m in \u001b[0;36mdetachFromDevice\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_attached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreatePoptorchError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Device is not attached\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0;31m# Read all the states back before detaching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: 'poptorch_py_error': Device is not attached"
     ]
    }
   ],
   "source": [
    "sentiment_pipeline.model.detachFromDevice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:47:38.097758Z",
     "iopub.status.busy": "2023-01-15T22:47:38.097508Z",
     "iopub.status.idle": "2023-01-15T22:47:38.342809Z",
     "shell.execute_reply": "2023-01-15T22:47:38.342050Z",
     "shell.execute_reply.started": "2023-01-15T22:47:38.097740Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_pipeline_2.model.detachFromDevice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:47:48.675120Z",
     "iopub.status.busy": "2023-01-15T22:47:48.674869Z",
     "iopub.status.idle": "2023-01-15T22:47:49.046446Z",
     "shell.execute_reply": "2023-01-15T22:47:49.045492Z",
     "shell.execute_reply.started": "2023-01-15T22:47:48.675101Z"
    }
   },
   "outputs": [],
   "source": [
    "!gc-monitor --no-card-info | grep ${os.getpid()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method has freed up the IPU resources while keeping the pipeline object available, meaning that we can quickly reattach the same pipeline to an IPU simply by calling it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:47:56.558137Z",
     "iopub.status.busy": "2023-01-15T22:47:56.557854Z",
     "iopub.status.idle": "2023-01-15T22:47:56.561353Z",
     "shell.execute_reply": "2023-01-15T22:47:56.560721Z",
     "shell.execute_reply.started": "2023-01-15T22:47:56.558115Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_test_data=[\"I love you.\", \"I hate you!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:48:54.620580Z",
     "iopub.status.busy": "2023-01-15T22:48:54.620295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.69 s, sys: 1.41 s, total: 3.1 s\n",
      "Wall time: 4.57 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998711347579956},\n",
       " {'label': 'NEGATIVE', 'score': 0.9987004995346069}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sentiment_pipeline(simple_test_data)\n",
    "\n",
    "# sentiment_pipeline.model.detachFromDevice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:49:18.296868Z",
     "iopub.status.busy": "2023-01-15T22:49:18.296618Z",
     "iopub.status.idle": "2023-01-15T22:49:18.310367Z",
     "shell.execute_reply": "2023-01-15T22:49:18.309262Z",
     "shell.execute_reply.started": "2023-01-15T22:49:18.296848Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentiment_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-b1e00cff934f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0msentiment_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sentiment_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "del sentiment_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:49:20.012976Z",
     "iopub.status.busy": "2023-01-15T22:49:20.012772Z",
     "iopub.status.idle": "2023-01-15T22:49:20.381807Z",
     "shell.execute_reply": "2023-01-15T22:49:20.381010Z",
     "shell.execute_reply.started": "2023-01-15T22:49:20.012955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  1119  |...3| 15m22s |    root    | 0  | 1330MHz  | 36.2 C | 27.9 C |153.3 W |\n",
      "|  1119  |...3| 15m22s |    root    | 1  | 1330MHz  | 33.0 C |        |        |\n"
     ]
    }
   ],
   "source": [
    "!gc-monitor --no-card-info | grep ${os.getpid()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first call is slow as the model is loaded onto the accelerator, but subsequent calls will be fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:49:23.289387Z",
     "iopub.status.busy": "2023-01-15T22:49:23.289117Z",
     "iopub.status.idle": "2023-01-15T22:49:23.303343Z",
     "shell.execute_reply": "2023-01-15T22:49:23.302758Z",
     "shell.execute_reply.started": "2023-01-15T22:49:23.289366Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentiment_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentiment_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentiment_pipeline(simple_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way to release resources is to let the `sentiment_pipeline` Python variable go out of scope.\n",
    "There are two main ways to do that:\n",
    "\n",
    "1. if you want to use the resources for another pipeline you can assign another variable to the same name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline = sentiment_pipeline_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gc-monitor --no-card-info | grep ${os.getpid()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explicitly use `del` to delete the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:49:28.928831Z",
     "iopub.status.busy": "2023-01-15T22:49:28.928583Z",
     "iopub.status.idle": "2023-01-15T22:49:28.938219Z",
     "shell.execute_reply": "2023-01-15T22:49:28.937236Z",
     "shell.execute_reply.started": "2023-01-15T22:49:28.928812Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentiment_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-2928039ceb93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Note that after the assignment sentiment_pipeline and sentiment_pipeline_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# refer to the same object so both symbols must be deleted to release the resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0msentiment_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0msentiment_pipeline_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentiment_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# Note that after the assignment sentiment_pipeline and sentiment_pipeline_2\n",
    "# refer to the same object so both symbols must be deleted to release the resources\n",
    "del sentiment_pipeline\n",
    "del sentiment_pipeline_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T22:49:31.165490Z",
     "iopub.status.busy": "2023-01-15T22:49:31.165256Z",
     "iopub.status.idle": "2023-01-15T22:49:31.536949Z",
     "shell.execute_reply": "2023-01-15T22:49:31.536213Z",
     "shell.execute_reply.started": "2023-01-15T22:49:31.165467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  1119  |...3| 15m34s |    root    | 0  | 1330MHz  | 36.1 C | 27.9 C |153.3 W |\n",
      "|  1119  |...3| 15m34s |    root    | 1  | 1330MHz  | 32.9 C |        |        |\n"
     ]
    }
   ],
   "source": [
    "!gc-monitor --no-card-info | grep ${os.getpid()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, no IPUs are used by the process anymore.\n",
    "\n",
    "Alternatively, all IPUs will be released when the notebook kernel is restarted. This can be done from the Notebook graphical user interface by clicking on `Kernel > Restart`:\n",
    "\n",
    "![Restart ipykernel](images/restart_kernel.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this simple tutorial we saw how to manage IPU resources from a notebook to make sure that we do not try to use more IPUs than are available on a single system.\n",
    "\n",
    "For more information on using IPUs and the Poplar SDK through Jupyter notebooks please see the our [dedicated guide](https://github.com/graphcore/tutorials/tree/master/tutorials/standard_tools/using_jupyter)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "46bde714a99d715eba7e507975e678b0968e7177d805932276a51e552e29fed0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
